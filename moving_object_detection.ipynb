{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPJYHMsPoK3OweLCmwy6H6C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkstar444/moving-object-detection/blob/main/moving_object_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **installs model**"
      ],
      "metadata": {
        "id": "d0U26iAhlRD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "9jwvnfIAgorM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "6c4P_Xwogr5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6msHdg9dy07A"
      },
      "outputs": [],
      "source": [
        "! pip install opencv-python gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "id": "CgVi6jdJhDOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pip install method (recommended)\n",
        "\n",
        "!pip install ultralytics==8.2.103 -q\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "id": "1LPf1Yh6hF0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YSf_TCWqlrAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **import library's**"
      ],
      "metadata": {
        "id": "5cuurBVVlrmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports and function definitions\n",
        "\n",
        "# For running inference on the TF-Hub module.\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# For downloading the image.\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO\n",
        "\n",
        "# For drawing onto the image.\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "\n",
        "# For measuring the inference time.\n",
        "import time\n",
        "\n",
        "# Print Tensorflow version\n",
        "print(tf.__version__)\n",
        "\n",
        "# Check available GPU devices.\n",
        "print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())"
      ],
      "metadata": {
        "id": "Xha-CkHtxzHm",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image\n",
        "\n",
        "import cv2\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "4rHHDEn584o0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iqWxdkvJ9CPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model**"
      ],
      "metadata": {
        "id": "Z12dAQrLmGv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def vid_inf(vid_path):\n",
        "    # Load the YOLO model (you can choose a specific model like 'yolov8n.pt')\n",
        "    model = YOLO('yolov8n.pt')  # or 'yolov5s.pt', etc.\n",
        "\n",
        "    # Create a VideoCapture object\n",
        "    cap = cv2.VideoCapture(vid_path)\n",
        "\n",
        "    # Get the video frames' width and height for proper saving of videos\n",
        "    frame_width = int(cap.get(3))\n",
        "    frame_height = int(cap.get(4))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    frame_size = (frame_width, frame_height)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    output_video = \"output_recorded.mp4\"\n",
        "\n",
        "    # Create the VideoWriter object\n",
        "    out = cv2.VideoWriter(output_video, fourcc, fps, frame_size)\n",
        "\n",
        "    # Check if camera opened successfully\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error opening video file\")\n",
        "        return None, None\n",
        "\n",
        "    count = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if ret:\n",
        "            # Perform object detection\n",
        "            results = model(frame)\n",
        "\n",
        "            # Draw bounding boxes and labels on the frame\n",
        "            for result in results:\n",
        "                boxes = result.boxes  # Get boxes\n",
        "                for box in boxes:\n",
        "                    x1, y1, x2, y2 = box.xyxy[0]  # Get box coordinates\n",
        "                    conf = box.conf[0]  # Get confidence\n",
        "                    cls = int(box.cls[0])  # Get class index\n",
        "                    label = f'{model.names[cls]}: {conf:.2f}'  # Class name and confidence\n",
        "\n",
        "                    # Draw rectangle and label on the frame\n",
        "                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
        "                    cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "            # Write the processed frame to the output video\n",
        "            out.write(frame)\n",
        "\n",
        "            # Convert frame for display\n",
        "            frame_out_display = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Update the count every frame and yield every 12th frame\n",
        "            if count % 12 == 0:\n",
        "                yield frame_out_display, None\n",
        "\n",
        "            count += 1\n",
        "\n",
        "            # Press Q on keyboard to exit\n",
        "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "                break\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # Release the video capture and writer object\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    yield None, output_video\n",
        "\n",
        "# Gradio interface\n",
        "input_video = gr.Video(label=\"Input Video\")\n",
        "output_frames = gr.Image(label=\"Output Frames\")\n",
        "output_video_file = gr.Video(label=\"Output video\")\n",
        "\n",
        "app = gr.Interface(\n",
        "    fn=vid_inf,\n",
        "    inputs=[input_video],\n",
        "    outputs=[output_frames, output_video_file],\n",
        "    title=\"MotionScope with YOLO\",\n",
        "    description='A Gradio app for dynamic video analysis using YOLO object detection to identify and track moving objects in real-time.',\n",
        "    allow_flagging=\"never\",\n",
        "    examples=[[\"sample/car.mp4\"]],\n",
        ")\n",
        "\n",
        "app.queue().launch()"
      ],
      "metadata": {
        "id": "GPiCIsjcj-6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z8ZgDbRCj-1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DMfeTO6U9CML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yEvtnmoG6JeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N8PCXqil802f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QB_q5Azz6JbF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}